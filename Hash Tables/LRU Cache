Design Problem

A cache is a memory that stores data for it to be served faster in the future.
Its purpose is to speed up data requests.
Least Recently Used(LRU) is a policy that is used to remove items from the cache.
Stacks follow the LIFO policy, queues follow the FIFO policy, a cache can follow the LRU policy.
Want to add a new item in the cache, where would we add it. 
Remove the least recently used item(last item of the list).
LRU cache follows the LRU principle.
The functions get and put must each run in O(1) average time complexity.

What data structures? for fast lookups(Hash Maps) and fast removals(double ended queues).

LRU defines the replacement policy when the cache is full and paging fault occurs.
Evict the least recently/ oldest request first. others will be shifted = the newest to the end.

Optimization: Eliminate shifting( Use doubly Linked List): Move left and right in constnt time.
Shifting: O(1)
Searching: O(N)
for q queries, Time: O(Q.N)

class Node:
    def __init__(self,key,val):
        self.key,self.val=key,val
        self.prev= self.next = None

class LRUCache:

    def __init__(self, capacity: int):
        self.cap= capacity
        self.cache= {} #maps keys to the nodes
        # left = LRU , right= Most Recent
        self.left , self.right = Node(0,0),Node(0,0)
        self.left.next, self.right.prev = self.right, self.left
    
    def remove(self,node): # remove from the list
        prev , nxt = node.prev, node.next
        prev.next, nxt.prev= nxt, prev
        
    def insert(self,node): #insert at right
        prev, nxt = self.right.prev, self.right
        prev.next= nxt.prev = node
        node.next,node.prev=nxt,prev
        
    def get(self, key: int) -> int:
        # the function returns the value for the key and reorders the cache
        if key in self.cache:
            # update the value to most recent
            self.remove(self.cache[key])
            self.insert(self.cache[key])
            return self.cache[key].val
        return -1

    def put(self, key: int, value: int) -> None:
        if key in self.cache:
            self.remove(self.cache[key])
            
        self.cache[key]=Node(key,value)
        self.insert(self.cache[key])
        if len(self.cache)>self.cap:
            lru= self.left.next
            self.remove(lru)
            del self.cache[lru.key]


# Your LRUCache object will be instantiated and called as such:
# obj = LRUCache(capacity)
# param_1 = obj.get(key)
# obj.put(key,value)

